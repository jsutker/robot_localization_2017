    #Project Writeup
    ###Gabriel Butterick and Joseph Sutker

    ##Goal
    The goal of the robot localization project was to gain an understanding of particle fields, implement a basic version of one, and effectively keep track of a robot's position in a room.

    ##Implementation
    Our basic implementation had little noise on particle placement or orientation, as well as fairly rudimentary weighting techniques. This resulted in position predictions that barely stuck to the actual position and quickly became lost and confused. The small variation from noise was insufficient to recover even from minor errors. Over the course of many iterations and a substantial amount of educated trial and error, we raised the noise to 80% variance for distance and 20% orientation variance, combined with changing the way weighting is calculated. The new way squared the result of 1/distance_between_map_and_measured, which made the weighting prioritize higher, more accurate values and nearly disregard the others. We also began using weighted random sampling to determine which particles to keep which performed much better than our original implementation that simply had a weight cutoff in which particles were eliminated only when they dropped below a specific value. Originally, we had thought the cutoff would eliminate the unlikely particles that we didn't want anyway and only leave particles that our model had a lot of faith in. The trouble was, there were many particles that all had a lot of weight, so the field became fairly divided. Changing to the random sampling version not only usually grabbed the higher weight particles but also allowed some minor representation from less likely particles, which caused minor, but important changes.

    ##Challenges
    Many of the challenges we faced in the early parts of testing stemmed from accidentally inverting math equations, like when we weighted incorrect particles higher than correct ones, or misunderstanding the way information was being presented, like how theta was determined. We realized particles were being weighted opposite the way they were supposed to when the model always clung to walls instead of following the arrow like intended. The theta issue was more complicated, however. We realized after a lot of testing that there were two directions our model would not move in under any circumstances. Through a large amount of trial and error, we realized that our logic, that determined the sign of the change in distance to add, didn't account for the zero to two pi range, instead the negative pi to pi range. Once that was sorted, our model performed almost admirably.

    ##Future Work
    We really thought we could make the weighting system much better if we could connect the degree value of the laser scan readings to those that would be expected on the map. The main issue we kept running into was when the model would guess the wrong path based on proximity alone and never be able to recover. If the model could tell which degree of the sensor should be seeing a proximity, there would be little chance that it would choose the wrong way. As far as tuning goes, we believe we tuned about as well as we could have.

    ##Lessons Learned
    This project made quite a few pitfalls more than easy to fall into, not the least of which was data assumption. An important takeaway was that you can never assume you know the way information is being provided to you. Checking the way things are presented helps make the logic surrounding it more universally effective. We learned that robot localization is really interesting, but also very complex. Perhaps if we had a while to study ways of refining particle filters, we would have been able to adapt more. This is an important lesson in how necessary research is. Puzzling on a problem that you lack the tools to solve is usually fruitless, and the earlier you begin seeking out appropriate literature, help, and examples, the better.
